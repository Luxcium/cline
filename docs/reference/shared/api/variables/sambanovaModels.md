[**claude-dev**](../../../README.md)

***

[claude-dev](../../../README.md) / [shared/api](../README.md) / sambanovaModels

# Variable: sambanovaModels

> `const` **sambanovaModels**: `object`

Defined in: src/shared/api.ts:2532

## Type declaration

### DeepSeek-R1

> `readonly` **DeepSeek-R1**: `object`

#### DeepSeek-R1.contextWindow

> `readonly` **contextWindow**: `16000` = `16_000`

#### DeepSeek-R1.inputPrice

> `readonly` **inputPrice**: `5` = `5.0`

#### DeepSeek-R1.maxTokens

> `readonly` **maxTokens**: `4096` = `4096`

#### DeepSeek-R1.outputPrice

> `readonly` **outputPrice**: `7` = `7.0`

#### DeepSeek-R1.supportsImages

> `readonly` **supportsImages**: `false` = `false`

#### DeepSeek-R1.supportsPromptCache

> `readonly` **supportsPromptCache**: `false` = `false`

### DeepSeek-R1-Distill-Llama-70B

> `readonly` **DeepSeek-R1-Distill-Llama-70B**: `object`

#### DeepSeek-R1-Distill-Llama-70B.contextWindow

> `readonly` **contextWindow**: `128000` = `128_000`

#### DeepSeek-R1-Distill-Llama-70B.inputPrice

> `readonly` **inputPrice**: `0.7` = `0.7`

#### DeepSeek-R1-Distill-Llama-70B.maxTokens

> `readonly` **maxTokens**: `4096` = `4096`

#### DeepSeek-R1-Distill-Llama-70B.outputPrice

> `readonly` **outputPrice**: `1.4` = `1.4`

#### DeepSeek-R1-Distill-Llama-70B.supportsImages

> `readonly` **supportsImages**: `false` = `false`

#### DeepSeek-R1-Distill-Llama-70B.supportsPromptCache

> `readonly` **supportsPromptCache**: `false` = `false`

### DeepSeek-V3-0324

> `readonly` **DeepSeek-V3-0324**: `object`

#### DeepSeek-V3-0324.contextWindow

> `readonly` **contextWindow**: `8000` = `8_000`

#### DeepSeek-V3-0324.inputPrice

> `readonly` **inputPrice**: `3` = `3.0`

#### DeepSeek-V3-0324.maxTokens

> `readonly` **maxTokens**: `4096` = `4096`

#### DeepSeek-V3-0324.outputPrice

> `readonly` **outputPrice**: `4.5` = `4.5`

#### DeepSeek-V3-0324.supportsImages

> `readonly` **supportsImages**: `false` = `false`

#### DeepSeek-V3-0324.supportsPromptCache

> `readonly` **supportsPromptCache**: `false` = `false`

### Llama-4-Maverick-17B-128E-Instruct

> `readonly` **Llama-4-Maverick-17B-128E-Instruct**: `object`

#### Llama-4-Maverick-17B-128E-Instruct.contextWindow

> `readonly` **contextWindow**: `8000` = `8_000`

#### Llama-4-Maverick-17B-128E-Instruct.inputPrice

> `readonly` **inputPrice**: `0.63` = `0.63`

#### Llama-4-Maverick-17B-128E-Instruct.maxTokens

> `readonly` **maxTokens**: `4096` = `4096`

#### Llama-4-Maverick-17B-128E-Instruct.outputPrice

> `readonly` **outputPrice**: `1.8` = `1.8`

#### Llama-4-Maverick-17B-128E-Instruct.supportsImages

> `readonly` **supportsImages**: `true` = `true`

#### Llama-4-Maverick-17B-128E-Instruct.supportsPromptCache

> `readonly` **supportsPromptCache**: `false` = `false`

### Llama-4-Scout-17B-16E-Instruct

> `readonly` **Llama-4-Scout-17B-16E-Instruct**: `object`

#### Llama-4-Scout-17B-16E-Instruct.contextWindow

> `readonly` **contextWindow**: `8000` = `8_000`

#### Llama-4-Scout-17B-16E-Instruct.inputPrice

> `readonly` **inputPrice**: `0.4` = `0.4`

#### Llama-4-Scout-17B-16E-Instruct.maxTokens

> `readonly` **maxTokens**: `4096` = `4096`

#### Llama-4-Scout-17B-16E-Instruct.outputPrice

> `readonly` **outputPrice**: `0.7` = `0.7`

#### Llama-4-Scout-17B-16E-Instruct.supportsImages

> `readonly` **supportsImages**: `false` = `false`

#### Llama-4-Scout-17B-16E-Instruct.supportsPromptCache

> `readonly` **supportsPromptCache**: `false` = `false`

#### Meta-Llama-3.1-405B-Instruct

> `readonly` **Meta-Llama-3.1-405B-Instruct**: `object`

#### Meta-Llama-3.1-405B-Instruct.contextWindow

> `readonly` **contextWindow**: `16000` = `16_000`

#### Meta-Llama-3.1-405B-Instruct.inputPrice

> `readonly` **inputPrice**: `5` = `5.0`

#### Meta-Llama-3.1-405B-Instruct.maxTokens

> `readonly` **maxTokens**: `4096` = `4096`

#### Meta-Llama-3.1-405B-Instruct.outputPrice

> `readonly` **outputPrice**: `10` = `10.0`

#### Meta-Llama-3.1-405B-Instruct.supportsImages

> `readonly` **supportsImages**: `false` = `false`

#### Meta-Llama-3.1-405B-Instruct.supportsPromptCache

> `readonly` **supportsPromptCache**: `false` = `false`

#### Meta-Llama-3.1-8B-Instruct

> `readonly` **Meta-Llama-3.1-8B-Instruct**: `object`

#### Meta-Llama-3.1-8B-Instruct.contextWindow

> `readonly` **contextWindow**: `16000` = `16_000`

#### Meta-Llama-3.1-8B-Instruct.inputPrice

> `readonly` **inputPrice**: `0.1` = `0.1`

#### Meta-Llama-3.1-8B-Instruct.maxTokens

> `readonly` **maxTokens**: `4096` = `4096`

#### Meta-Llama-3.1-8B-Instruct.outputPrice

> `readonly` **outputPrice**: `0.2` = `0.2`

#### Meta-Llama-3.1-8B-Instruct.supportsImages

> `readonly` **supportsImages**: `false` = `false`

#### Meta-Llama-3.1-8B-Instruct.supportsPromptCache

> `readonly` **supportsPromptCache**: `false` = `false`

#### Meta-Llama-3.2-1B-Instruct

> `readonly` **Meta-Llama-3.2-1B-Instruct**: `object`

#### Meta-Llama-3.2-1B-Instruct.contextWindow

> `readonly` **contextWindow**: `16000` = `16_000`

#### Meta-Llama-3.2-1B-Instruct.inputPrice

> `readonly` **inputPrice**: `0.04` = `0.04`

#### Meta-Llama-3.2-1B-Instruct.maxTokens

> `readonly` **maxTokens**: `4096` = `4096`

#### Meta-Llama-3.2-1B-Instruct.outputPrice

> `readonly` **outputPrice**: `0.08` = `0.08`

#### Meta-Llama-3.2-1B-Instruct.supportsImages

> `readonly` **supportsImages**: `false` = `false`

#### Meta-Llama-3.2-1B-Instruct.supportsPromptCache

> `readonly` **supportsPromptCache**: `false` = `false`

#### Meta-Llama-3.2-3B-Instruct

> `readonly` **Meta-Llama-3.2-3B-Instruct**: `object`

#### Meta-Llama-3.2-3B-Instruct.contextWindow

> `readonly` **contextWindow**: `8000` = `8_000`

#### Meta-Llama-3.2-3B-Instruct.inputPrice

> `readonly` **inputPrice**: `0.08` = `0.08`

#### Meta-Llama-3.2-3B-Instruct.maxTokens

> `readonly` **maxTokens**: `4096` = `4096`

#### Meta-Llama-3.2-3B-Instruct.outputPrice

> `readonly` **outputPrice**: `0.16` = `0.16`

#### Meta-Llama-3.2-3B-Instruct.supportsImages

> `readonly` **supportsImages**: `false` = `false`

#### Meta-Llama-3.2-3B-Instruct.supportsPromptCache

> `readonly` **supportsPromptCache**: `false` = `false`

#### Meta-Llama-3.3-70B-Instruct

> `readonly` **Meta-Llama-3.3-70B-Instruct**: `object`

#### Meta-Llama-3.3-70B-Instruct.contextWindow

> `readonly` **contextWindow**: `128000` = `128_000`

#### Meta-Llama-3.3-70B-Instruct.inputPrice

> `readonly` **inputPrice**: `0.6` = `0.6`

#### Meta-Llama-3.3-70B-Instruct.maxTokens

> `readonly` **maxTokens**: `4096` = `4096`

#### Meta-Llama-3.3-70B-Instruct.outputPrice

> `readonly` **outputPrice**: `1.2` = `1.2`

#### Meta-Llama-3.3-70B-Instruct.supportsImages

> `readonly` **supportsImages**: `false` = `false`

#### Meta-Llama-3.3-70B-Instruct.supportsPromptCache

> `readonly` **supportsPromptCache**: `false` = `false`

### Qwen3-32B

> `readonly` **Qwen3-32B**: `object`

#### Qwen3-32B.contextWindow

> `readonly` **contextWindow**: `16000` = `16_000`

#### Qwen3-32B.inputPrice

> `readonly` **inputPrice**: `0.4` = `0.4`

#### Qwen3-32B.maxTokens

> `readonly` **maxTokens**: `4096` = `4096`

#### Qwen3-32B.outputPrice

> `readonly` **outputPrice**: `0.8` = `0.8`

#### Qwen3-32B.supportsImages

> `readonly` **supportsImages**: `false` = `false`

#### Qwen3-32B.supportsPromptCache

> `readonly` **supportsPromptCache**: `false` = `false`

### QwQ-32B

> `readonly` **QwQ-32B**: `object`

#### QwQ-32B.contextWindow

> `readonly` **contextWindow**: `16000` = `16_000`

#### QwQ-32B.inputPrice

> `readonly` **inputPrice**: `0.5` = `0.5`

#### QwQ-32B.maxTokens

> `readonly` **maxTokens**: `4096` = `4096`

#### QwQ-32B.outputPrice

> `readonly` **outputPrice**: `1` = `1.0`

#### QwQ-32B.supportsImages

> `readonly` **supportsImages**: `false` = `false`

#### QwQ-32B.supportsPromptCache

> `readonly` **supportsPromptCache**: `false` = `false`
