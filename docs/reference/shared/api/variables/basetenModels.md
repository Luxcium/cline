[**claude-dev**](../../../README.md)

***

[claude-dev](../../../README.md) / [shared/api](../README.md) / basetenModels

# Variable: basetenModels

> `const` **basetenModels**: `object`

Defined in: src/shared/api.ts:3102

## Type declaration

### deepseek-ai/DeepSeek-R1-0528

> `readonly` **deepseek-ai/DeepSeek-R1-0528**: `object`

#### deepseek-ai/DeepSeek-R1-0528.cacheReadsPrice

> `readonly` **cacheReadsPrice**: `0` = `0`

#### deepseek-ai/DeepSeek-R1-0528.cacheWritesPrice

> `readonly` **cacheWritesPrice**: `0` = `0`

#### deepseek-ai/DeepSeek-R1-0528.contextWindow

> `readonly` **contextWindow**: `163840` = `163840`

#### deepseek-ai/DeepSeek-R1-0528.description

> `readonly` **description**: `"DeepSeek R1 0528 - A state-of-the-art 671B-parameter MoE LLM with o1-style reasoning licensed for commercial use."` = `"DeepSeek R1 0528 - A state-of-the-art 671B-parameter MoE LLM with o1-style reasoning licensed for commercial use."`

#### deepseek-ai/DeepSeek-R1-0528.inputPrice

> `readonly` **inputPrice**: `2.55` = `2.55`

#### deepseek-ai/DeepSeek-R1-0528.maxTokens

> `readonly` **maxTokens**: `131072` = `131072`

#### deepseek-ai/DeepSeek-R1-0528.outputPrice

> `readonly` **outputPrice**: `5.95` = `5.95`

#### deepseek-ai/DeepSeek-R1-0528.supportsImages

> `readonly` **supportsImages**: `false` = `false`

#### deepseek-ai/DeepSeek-R1-0528.supportsPromptCache

> `readonly` **supportsPromptCache**: `false` = `false`

### deepseek-ai/DeepSeek-V3-0324

> `readonly` **deepseek-ai/DeepSeek-V3-0324**: `object`

#### deepseek-ai/DeepSeek-V3-0324.cacheReadsPrice

> `readonly` **cacheReadsPrice**: `0` = `0`

#### deepseek-ai/DeepSeek-V3-0324.cacheWritesPrice

> `readonly` **cacheWritesPrice**: `0` = `0`

#### deepseek-ai/DeepSeek-V3-0324.contextWindow

> `readonly` **contextWindow**: `163840` = `163840`

#### deepseek-ai/DeepSeek-V3-0324.description

> `readonly` **description**: `"DeepSeek V3 0324 - A state-of-the-art 671B-parameter MoE LLM licensed for commercial use."` = `"DeepSeek V3 0324 - A state-of-the-art 671B-parameter MoE LLM licensed for commercial use."`

#### deepseek-ai/DeepSeek-V3-0324.inputPrice

> `readonly` **inputPrice**: `0.77` = `0.77`

#### deepseek-ai/DeepSeek-V3-0324.maxTokens

> `readonly` **maxTokens**: `131072` = `131072`

#### deepseek-ai/DeepSeek-V3-0324.outputPrice

> `readonly` **outputPrice**: `0.77` = `0.77`

#### deepseek-ai/DeepSeek-V3-0324.supportsImages

> `readonly` **supportsImages**: `false` = `false`

#### deepseek-ai/DeepSeek-V3-0324.supportsPromptCache

> `readonly` **supportsPromptCache**: `false` = `false`

### meta-llama/Llama-4-Maverick-17B-128E-Instruct

> `readonly` **meta-llama/Llama-4-Maverick-17B-128E-Instruct**: `object`

#### meta-llama/Llama-4-Maverick-17B-128E-Instruct.cacheReadsPrice

> `readonly` **cacheReadsPrice**: `0` = `0`

#### meta-llama/Llama-4-Maverick-17B-128E-Instruct.cacheWritesPrice

> `readonly` **cacheWritesPrice**: `0` = `0`

#### meta-llama/Llama-4-Maverick-17B-128E-Instruct.contextWindow

> `readonly` **contextWindow**: `131072` = `131072`

#### meta-llama/Llama-4-Maverick-17B-128E-Instruct.description

> `readonly` **description**: `"Meta's Llama 4 Maverick - A SOTA mixture-of-experts multi-modal LLM with 400 billion total parameters."` = `"Meta's Llama 4 Maverick - A SOTA mixture-of-experts multi-modal LLM with 400 billion total parameters."`

#### meta-llama/Llama-4-Maverick-17B-128E-Instruct.inputPrice

> `readonly` **inputPrice**: `0.19` = `0.19`

#### meta-llama/Llama-4-Maverick-17B-128E-Instruct.maxTokens

> `readonly` **maxTokens**: `8192` = `8192`

#### meta-llama/Llama-4-Maverick-17B-128E-Instruct.outputPrice

> `readonly` **outputPrice**: `0.72` = `0.72`

#### meta-llama/Llama-4-Maverick-17B-128E-Instruct.supportsImages

> `readonly` **supportsImages**: `false` = `false`

#### meta-llama/Llama-4-Maverick-17B-128E-Instruct.supportsPromptCache

> `readonly` **supportsPromptCache**: `false` = `false`

### meta-llama/Llama-4-Scout-17B-16E-Instruct

> `readonly` **meta-llama/Llama-4-Scout-17B-16E-Instruct**: `object`

#### meta-llama/Llama-4-Scout-17B-16E-Instruct.cacheReadsPrice

> `readonly` **cacheReadsPrice**: `0` = `0`

#### meta-llama/Llama-4-Scout-17B-16E-Instruct.cacheWritesPrice

> `readonly` **cacheWritesPrice**: `0` = `0`

#### meta-llama/Llama-4-Scout-17B-16E-Instruct.contextWindow

> `readonly` **contextWindow**: `131072` = `131072`

#### meta-llama/Llama-4-Scout-17B-16E-Instruct.description

> `readonly` **description**: `"Meta's Llama 4 Scout - A SOTA mixture-of-experts multi-modal LLM with 109 billion total parameters."` = `"Meta's Llama 4 Scout - A SOTA mixture-of-experts multi-modal LLM with 109 billion total parameters."`

#### meta-llama/Llama-4-Scout-17B-16E-Instruct.inputPrice

> `readonly` **inputPrice**: `0.13` = `0.13`

#### meta-llama/Llama-4-Scout-17B-16E-Instruct.maxTokens

> `readonly` **maxTokens**: `8192` = `8192`

#### meta-llama/Llama-4-Scout-17B-16E-Instruct.outputPrice

> `readonly` **outputPrice**: `0.5` = `0.5`

#### meta-llama/Llama-4-Scout-17B-16E-Instruct.supportsImages

> `readonly` **supportsImages**: `false` = `false`

#### meta-llama/Llama-4-Scout-17B-16E-Instruct.supportsPromptCache

> `readonly` **supportsPromptCache**: `false` = `false`

### moonshotai/Kimi-K2-Instruct

> `readonly` **moonshotai/Kimi-K2-Instruct**: `object`

#### moonshotai/Kimi-K2-Instruct.cacheReadsPrice

> `readonly` **cacheReadsPrice**: `0` = `0`

#### moonshotai/Kimi-K2-Instruct.cacheWritesPrice

> `readonly` **cacheWritesPrice**: `0` = `0`

#### moonshotai/Kimi-K2-Instruct.contextWindow

> `readonly` **contextWindow**: `131072` = `131072`

#### moonshotai/Kimi-K2-Instruct.description

> `readonly` **description**: `"Moonshot AI's Kimi K2 - The world's first 1 trillion parameter open source model."` = `"Moonshot AI's Kimi K2 - The world's first 1 trillion parameter open source model."`

#### moonshotai/Kimi-K2-Instruct.inputPrice

> `readonly` **inputPrice**: `0.6` = `0.6`

#### moonshotai/Kimi-K2-Instruct.maxTokens

> `readonly` **maxTokens**: `131072` = `131072`

#### moonshotai/Kimi-K2-Instruct.outputPrice

> `readonly` **outputPrice**: `2.5` = `2.5`

#### moonshotai/Kimi-K2-Instruct.supportsImages

> `readonly` **supportsImages**: `false` = `false`

#### moonshotai/Kimi-K2-Instruct.supportsPromptCache

> `readonly` **supportsPromptCache**: `false` = `false`

### Qwen/Qwen3-235B-A22B-Instruct-2507

> `readonly` **Qwen/Qwen3-235B-A22B-Instruct-2507**: `object`

#### Qwen/Qwen3-235B-A22B-Instruct-2507.cacheReadsPrice

> `readonly` **cacheReadsPrice**: `0` = `0`

#### Qwen/Qwen3-235B-A22B-Instruct-2507.cacheWritesPrice

> `readonly` **cacheWritesPrice**: `0` = `0`

#### Qwen/Qwen3-235B-A22B-Instruct-2507.contextWindow

> `readonly` **contextWindow**: `163800` = `163800`

#### Qwen/Qwen3-235B-A22B-Instruct-2507.description

> `readonly` **description**: `"Qwen3-235B-A22B-Instruct-2507 is a multilingual, instruction-tuned mixture-of-experts language model based on the Qwen3-235B architecture, with 22B active parameters per forward pass."` = `"Qwen3-235B-A22B-Instruct-2507 is a multilingual, instruction-tuned mixture-of-experts language model based on the Qwen3-235B architecture, with 22B active parameters per forward pass."`

#### Qwen/Qwen3-235B-A22B-Instruct-2507.inputPrice

> `readonly` **inputPrice**: `0.22` = `0.22`

#### Qwen/Qwen3-235B-A22B-Instruct-2507.maxTokens

> `readonly` **maxTokens**: `163800` = `163800`

#### Qwen/Qwen3-235B-A22B-Instruct-2507.outputPrice

> `readonly` **outputPrice**: `0.8` = `0.8`

#### Qwen/Qwen3-235B-A22B-Instruct-2507.supportsImages

> `readonly` **supportsImages**: `false` = `false`

#### Qwen/Qwen3-235B-A22B-Instruct-2507.supportsPromptCache

> `readonly` **supportsPromptCache**: `false` = `false`

### Qwen/Qwen3-Coder-480B-A35B-Instruct

> `readonly` **Qwen/Qwen3-Coder-480B-A35B-Instruct**: `object`

#### Qwen/Qwen3-Coder-480B-A35B-Instruct.cacheReadsPrice

> `readonly` **cacheReadsPrice**: `0` = `0`

#### Qwen/Qwen3-Coder-480B-A35B-Instruct.cacheWritesPrice

> `readonly` **cacheWritesPrice**: `0` = `0`

#### Qwen/Qwen3-Coder-480B-A35B-Instruct.contextWindow

> `readonly` **contextWindow**: `163800` = `163800`

#### Qwen/Qwen3-Coder-480B-A35B-Instruct.description

> `readonly` **description**: `"Qwen3-Coder-480B-A35B-Instruct is a 480B parameter, instruction-tuned, agentic coding model that excels at function calling, tool use, and long-context reasoning over repositories."` = `"Qwen3-Coder-480B-A35B-Instruct is a 480B parameter, instruction-tuned, agentic coding model that excels at function calling, tool use, and long-context reasoning over repositories."`

#### Qwen/Qwen3-Coder-480B-A35B-Instruct.inputPrice

> `readonly` **inputPrice**: `1.7` = `1.7`

#### Qwen/Qwen3-Coder-480B-A35B-Instruct.maxTokens

> `readonly` **maxTokens**: `163800` = `163800`

#### Qwen/Qwen3-Coder-480B-A35B-Instruct.outputPrice

> `readonly` **outputPrice**: `1.7` = `1.7`

#### Qwen/Qwen3-Coder-480B-A35B-Instruct.supportsImages

> `readonly` **supportsImages**: `false` = `false`

#### Qwen/Qwen3-Coder-480B-A35B-Instruct.supportsPromptCache

> `readonly` **supportsPromptCache**: `false` = `false`
