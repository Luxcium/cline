[**claude-dev**](../../../README.md)

***

[claude-dev](../../../README.md) / [shared/api](../README.md) / cerebrasModels

# Variable: cerebrasModels

> `const` **cerebrasModels**: `object`

Defined in: src/shared/api.ts:2635

## Type declaration

### gpt-oss-120b

> `readonly` **gpt-oss-120b**: `object`

#### gpt-oss-120b.contextWindow

> `readonly` **contextWindow**: `128000` = `128000`

#### gpt-oss-120b.description

> `readonly` **description**: `"Intelligent general purpose model with 3,000 tokens/s"` = `"Intelligent general purpose model with 3,000 tokens/s"`

#### gpt-oss-120b.inputPrice

> `readonly` **inputPrice**: `0` = `0`

#### gpt-oss-120b.maxTokens

> `readonly` **maxTokens**: `65536` = `65536`

#### gpt-oss-120b.outputPrice

> `readonly` **outputPrice**: `0` = `0`

#### gpt-oss-120b.supportsImages

> `readonly` **supportsImages**: `false` = `false`

#### gpt-oss-120b.supportsPromptCache

> `readonly` **supportsPromptCache**: `false` = `false`

#### llama-3.3-70b

> `readonly` **llama-3.3-70b**: `object`

#### llama-3.3-70b.contextWindow

> `readonly` **contextWindow**: `64000` = `64000`

#### llama-3.3-70b.description

> `readonly` **description**: `"Powerful model with ~2600 tokens/s"` = `"Powerful model with ~2600 tokens/s"`

#### llama-3.3-70b.inputPrice

> `readonly` **inputPrice**: `0` = `0`

#### llama-3.3-70b.maxTokens

> `readonly` **maxTokens**: `64000` = `64000`

#### llama-3.3-70b.outputPrice

> `readonly` **outputPrice**: `0` = `0`

#### llama-3.3-70b.supportsImages

> `readonly` **supportsImages**: `false` = `false`

#### llama-3.3-70b.supportsPromptCache

> `readonly` **supportsPromptCache**: `false` = `false`

### qwen-3-235b-a22b-instruct-2507

> `readonly` **qwen-3-235b-a22b-instruct-2507**: `object`

#### qwen-3-235b-a22b-instruct-2507.contextWindow

> `readonly` **contextWindow**: `64000` = `64000`

#### qwen-3-235b-a22b-instruct-2507.description

> `readonly` **description**: `"Intelligent model with ~1400 tokens/s"` = `"Intelligent model with ~1400 tokens/s"`

#### qwen-3-235b-a22b-instruct-2507.inputPrice

> `readonly` **inputPrice**: `0` = `0`

#### qwen-3-235b-a22b-instruct-2507.maxTokens

> `readonly` **maxTokens**: `64000` = `64000`

#### qwen-3-235b-a22b-instruct-2507.outputPrice

> `readonly` **outputPrice**: `0` = `0`

#### qwen-3-235b-a22b-instruct-2507.supportsImages

> `readonly` **supportsImages**: `false` = `false`

#### qwen-3-235b-a22b-instruct-2507.supportsPromptCache

> `readonly` **supportsPromptCache**: `false` = `false`

### qwen-3-235b-a22b-thinking-2507

> `readonly` **qwen-3-235b-a22b-thinking-2507**: `object`

#### qwen-3-235b-a22b-thinking-2507.contextWindow

> `readonly` **contextWindow**: `65000` = `65000`

#### qwen-3-235b-a22b-thinking-2507.description

> `readonly` **description**: `"SOTA performance with ~1500 tokens/s"` = `"SOTA performance with ~1500 tokens/s"`

#### qwen-3-235b-a22b-thinking-2507.inputPrice

> `readonly` **inputPrice**: `0` = `0`

#### qwen-3-235b-a22b-thinking-2507.maxTokens

> `readonly` **maxTokens**: `32000` = `32000`

#### qwen-3-235b-a22b-thinking-2507.outputPrice

> `readonly` **outputPrice**: `0` = `0`

#### qwen-3-235b-a22b-thinking-2507.supportsImages

> `readonly` **supportsImages**: `false` = `false`

#### qwen-3-235b-a22b-thinking-2507.supportsPromptCache

> `readonly` **supportsPromptCache**: `false` = `false`

### qwen-3-32b

> `readonly` **qwen-3-32b**: `object`

#### qwen-3-32b.contextWindow

> `readonly` **contextWindow**: `64000` = `64000`

#### qwen-3-32b.description

> `readonly` **description**: `"SOTA coding performance with ~2500 tokens/s"` = `"SOTA coding performance with ~2500 tokens/s"`

#### qwen-3-32b.inputPrice

> `readonly` **inputPrice**: `0` = `0`

#### qwen-3-32b.maxTokens

> `readonly` **maxTokens**: `64000` = `64000`

#### qwen-3-32b.outputPrice

> `readonly` **outputPrice**: `0` = `0`

#### qwen-3-32b.supportsImages

> `readonly` **supportsImages**: `false` = `false`

#### qwen-3-32b.supportsPromptCache

> `readonly` **supportsPromptCache**: `false` = `false`

### qwen-3-coder-480b

> `readonly` **qwen-3-coder-480b**: `object`

#### qwen-3-coder-480b.contextWindow

> `readonly` **contextWindow**: `128000` = `128000`

#### qwen-3-coder-480b.description

> `readonly` **description**: "SOTA coding model with ~2000 tokens/s ($50/$250 paid tiers)\n\n• Use this if you have a Cerebras subscription\n• 131K context window with higher rate limits" = `"SOTA coding model with ~2000 tokens/s ($50/$250 paid tiers)\n\n• Use this if you have a Cerebras subscription\n• 131K context window with higher rate limits"`

#### qwen-3-coder-480b.inputPrice

> `readonly` **inputPrice**: `0` = `0`

#### qwen-3-coder-480b.maxTokens

> `readonly` **maxTokens**: `40000` = `40000`

#### qwen-3-coder-480b.outputPrice

> `readonly` **outputPrice**: `0` = `0`

#### qwen-3-coder-480b.supportsImages

> `readonly` **supportsImages**: `false` = `false`

#### qwen-3-coder-480b.supportsPromptCache

> `readonly` **supportsPromptCache**: `false` = `false`

### qwen-3-coder-480b-free

> `readonly` **qwen-3-coder-480b-free**: `object`

#### qwen-3-coder-480b-free.contextWindow

> `readonly` **contextWindow**: `64000` = `64000`

#### qwen-3-coder-480b-free.description

> `readonly` **description**: "SOTA coding model with ~2000 tokens/s ($0 free tier)\n\n• Use this if you don't have a Cerebras subscription\n• 64K context window\n• Rate limits: 150K TPM, 1M TPH/TPD, 10 RPM, 100 RPH/RPD\n\nUpgrade for higher limits: \[https://cloud.cerebras.ai/?utm=cline\](https://cloud.cerebras.ai/?utm=cline)" = `"SOTA coding model with ~2000 tokens/s ($0 free tier)\n\n• Use this if you don't have a Cerebras subscription\n• 64K context window\n• Rate limits: 150K TPM, 1M TPH/TPD, 10 RPM, 100 RPH/RPD\n\nUpgrade for higher limits: [https://cloud.cerebras.ai/?utm=cline](https://cloud.cerebras.ai/?utm=cline)"`

#### qwen-3-coder-480b-free.inputPrice

> `readonly` **inputPrice**: `0` = `0`

#### qwen-3-coder-480b-free.maxTokens

> `readonly` **maxTokens**: `40000` = `40000`

#### qwen-3-coder-480b-free.outputPrice

> `readonly` **outputPrice**: `0` = `0`

#### qwen-3-coder-480b-free.supportsImages

> `readonly` **supportsImages**: `false` = `false`

#### qwen-3-coder-480b-free.supportsPromptCache

> `readonly` **supportsPromptCache**: `false` = `false`
